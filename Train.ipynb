{"cells":[{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"yzp8RFGAIp9N","outputId":"7d531514-e7ae-4c5a-8d2b-ac2d0cbdb834","executionInfo":{"status":"error","timestamp":1650393984302,"user_tz":-330,"elapsed":9102,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d05fe204dd76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 128\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["cd /content/gdrive/MyDrive/Mask-Rcnn-Tensorflow-2.0"],"metadata":{"id":"FmAXhGunJ3JX","executionInfo":{"status":"aborted","timestamp":1650393984282,"user_tz":-330,"elapsed":23,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"id":"rsf_4sQjJ91N","executionInfo":{"status":"aborted","timestamp":1650393984284,"user_tz":-330,"elapsed":25,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKmCFhLGImq3","executionInfo":{"status":"aborted","timestamp":1650393984285,"user_tz":-330,"elapsed":26,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"outputs":[],"source":["import tensorflow as tf\n","physical_devices = tf.config.list_physical_devices('GPU') \n","for gpu_instance in physical_devices: \n","    tf.config.experimental.set_memory_growth(gpu_instance, True)\n","\n","from tensorflow.compat.v1.keras.backend import set_session\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n","config.log_device_placement = True  # to log device placement (on which device the operation ran)\n","sess = tf.compat.v1.Session(config=config)\n","set_session(sess)\n","\n","\n","from PIL import Image    \n","import os, glob\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import shutil\n","import tensorflow as tf\n"]},{"cell_type":"code","source":["# Set the ROOT_DIR variable to the root directory of the Mask_RCNN git repo\n","ROOT_DIR = '/content/gdrive/MyDrive/Mask_RCNN'\n","assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist. Did you forget to read the instructions above? ;)'\n","\n","# Import mrcnn libraries\n","sys.path.append(ROOT_DIR) \n","from mrcnn.config import Config\n","import mrcnn.utils as utils\n","from mrcnn import visualize\n","import mrcnn.model as modellib"],"metadata":{"id":"tYdAw9R6I8lp","executionInfo":{"status":"aborted","timestamp":1650393984286,"user_tz":-330,"elapsed":26,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","# Local path to trained weights file\n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n","\n","# Download COCO trained weights from Releases if needed\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)"],"metadata":{"id":"7wQ5rjgEI_JO","executionInfo":{"status":"aborted","timestamp":1650393984288,"user_tz":-330,"elapsed":27,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AgFieldConfig(Config):\n","    \"\"\"Configuration for training on the AgField butts dataset.\n","    Derives from the base Config class and overrides values specific\n","    to the cigarette butts dataset.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"AgField\"\n","\n","    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 4\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # background + 1 (AgField)\n","\n","    # Use small images for faster training. Set the limits of the small side\n","    # the large side, and that determines the image shape.\n","    IMAGE_MIN_DIM = 256\n","    IMAGE_MAX_DIM = 256\n","\n","    # Use smaller anchors because our image and objects are small\n","    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n","\n","    # Reduce training ROIs per image because the images are small and have\n","    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n","    TRAIN_ROIS_PER_IMAGE = 60\n","\n","    # Use a small epoch since the data is simple\n","    STEPS_PER_EPOCH = 100\n","\n","    # use small validation steps since the epoch is small\n","    VALIDATION_STEPS = 5\n","\n","    LEARNING_RATE = 0.002\n","    \n","    #set the epochs \n","    HEAD_EPOCHS = 3\n","    ALL_EPOCHS = 40\n","\n","    #backbone\n","    BACKBONE = \"resnet50\"\n","    \n","config = AgFieldConfig()\n","config.display()"],"metadata":{"id":"xJpFcNhPJD0O","executionInfo":{"status":"aborted","timestamp":1650393984289,"user_tz":-330,"elapsed":28,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CocoLikeDataset(utils.Dataset):\n","    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n","        See http://cocodataset.org/#home for more information.\n","    \"\"\"\n","    def load_data(self, annotation_json, images_dir):\n","        \"\"\" Load the coco-like dataset from json\n","        Args:\n","            annotation_json: The path to the coco annotations json file\n","            images_dir: The directory holding the images referred to by the json file\n","        \"\"\"\n","        # Load json from file\n","        json_file = open(annotation_json)\n","        coco_json = json.load(json_file)\n","        json_file.close()\n","        \n","        # Add the class names using the base method from utils.Dataset\n","        source_name = \"coco_like\"\n","        for category in coco_json['categories']:\n","            class_id = category['id']\n","            class_name = category['name']\n","            if class_id < 1:\n","                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n","                return\n","            \n","            self.add_class(source_name, class_id, class_name)\n","        \n","        # Get all annotations\n","        annotations = {}\n","        for annotation in coco_json['annotations']:\n","            image_id = annotation['image_id']\n","            if image_id not in annotations:\n","                annotations[image_id] = []\n","            annotations[image_id].append(annotation)\n","        \n","        # Get all images and add them to the dataset\n","        seen_images = {}\n","        for image in coco_json['images']:\n","            image_id = image['id']\n","            if image_id in seen_images:\n","                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n","            else:\n","                seen_images[image_id] = image\n","                try:\n","                    image_file_name = image['file_name']\n","                    image_width = image['width']\n","                    image_height = image['height']\n","                except KeyError as key:\n","                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n","                \n","                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n","                image_annotations = annotations[image_id]\n","                \n","                # Add the image using the base method from utils.Dataset\n","                self.add_image(\n","                    source=source_name,\n","                    image_id=image_id,\n","                    path=image_path,\n","                    width=image_width,\n","                    height=image_height,\n","                    annotations=image_annotations\n","                )\n","                \n","    def load_mask(self, image_id):\n","        \"\"\" Load instance masks for the given image.\n","        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n","        Args:\n","            image_id: The id of the image to load masks for\n","        Returns:\n","            masks: A bool array of shape [height, width, instance count] with\n","                one mask per instance.\n","            class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        image_info = self.image_info[image_id]\n","        annotations = image_info['annotations']\n","        instance_masks = []\n","        class_ids = []\n","        \n","        for annotation in annotations:\n","            class_id = annotation['category_id']\n","            mask = Image.new('1', (image_info['width'], image_info['height']))\n","            mask_draw = ImageDraw.ImageDraw(mask, '1')\n","            for segmentation in annotation['segmentation']:\n","                mask_draw.polygon(segmentation, fill=1)\n","                bool_array = np.array(mask) > 0\n","                instance_masks.append(bool_array)\n","                class_ids.append(class_id)\n","\n","        mask = np.dstack(instance_masks)\n","        class_ids = np.array(class_ids, dtype=np.int32)\n","        \n","        return mask, class_ids"],"metadata":{"id":"mdS81pAxJPPZ","executionInfo":{"status":"aborted","timestamp":1650393984290,"user_tz":-330,"elapsed":29,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_train = CocoLikeDataset()\n","dataset_train.load_data('/content/gdrive/MyDrive/Mask_RCNN/datasets/annotations/annotations/train2016.json', '/content/gdrive/MyDrive/Mask_RCNN/datasets/images/images/train2016')\n","dataset_train.prepare()\n","\n","dataset_val = CocoLikeDataset()\n","dataset_val.load_data('/content/gdrive/MyDrive/Mask_RCNN/datasets/annotations/annotations/val2016.json', '/content/gdrive/MyDrive/Mask_RCNN/datasets/images/images/val2016')\n","dataset_val.prepare()"],"metadata":{"id":"XzMeng7OJeeB","executionInfo":{"status":"aborted","timestamp":1650393984292,"user_tz":-330,"elapsed":30,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image, ImageDraw\n","\n","dataset = dataset_train\n","image_ids = np.random.choice(dataset.image_ids, 4)\n","for image_id in image_ids:\n","    image = dataset.load_image(image_id)\n","    mask, class_ids = dataset.load_mask(image_id)\n","    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"],"metadata":{"id":"zRtDFs_5JmcV","executionInfo":{"status":"aborted","timestamp":1650393984292,"user_tz":-330,"elapsed":30,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model in training mode\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                          model_dir=MODEL_DIR)\n","\n","# if you want train continue, use the function find_last()\n","#\n","# Which weights to start with?\n","init_with = \"coco\"  # imagenet, coco, or last\n","\n","if init_with == \"imagenet\":\n","    model.load_weights(model.get_imagenet_weights(), by_name=True)\n","elif init_with == \"coco\":\n","    # Load weights trained on MS COCO, but skip layers that\n","    # are different due to the different number of classes\n","    # See README for instructions to download the COCO weights\n","    model.load_weights(COCO_MODEL_PATH, by_name=True,\n","                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n","                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n","elif init_with == \"last\":\n","    # Load the last model you trained and continue training\n","    model.load_weights(model.find_last(), by_name=True)"],"metadata":{"id":"gFBASnGJJnXj","executionInfo":{"status":"aborted","timestamp":1650393984293,"user_tz":-330,"elapsed":31,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the head branches\n","# Passing layers=\"heads\" freezes all layers except the head\n","# layers. You can also pass a regular expression to select\n","# which layers to train by name pattern.\n","model.train(dataset_train, dataset_val, \n","            learning_rate=config.LEARNING_RATE, \n","            epochs=config.HEAD_EPOCHS, \n","            layers='heads')\n","\n","\n","# Fine tune all layers\n","# Passing layers=\"all\" trains all layers. You can also \n","# pass a regular expression to select which layers to\n","# train by name pattern.\n","model.train(dataset_train, dataset_val, \n","            learning_rate=config.LEARNING_RATE / 10,\n","            epochs=config.ALL_EPOCHS, \n","            layers=\"all\")"],"metadata":{"id":"5y3i_58qJttP","executionInfo":{"status":"aborted","timestamp":1650393984296,"user_tz":-330,"elapsed":34,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class InferenceConfig(AgFieldConfig):\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    IMAGE_MIN_DIM = 256\n","    IMAGE_MAX_DIM = 256\n","    DETECTION_MIN_CONFIDENCE = 0.85\n","\n","inference_config = InferenceConfig()"],"metadata":{"id":"WsgCbXO9jOKK","executionInfo":{"status":"aborted","timestamp":1650393984298,"user_tz":-330,"elapsed":35,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = modellib.MaskRCNN(mode=\"inference\", \n","                          config=inference_config,\n","                          model_dir=MODEL_DIR)"],"metadata":{"id":"KipRAdLpjTU9","executionInfo":{"status":"aborted","timestamp":1650393984299,"user_tz":-330,"elapsed":36,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_ids = np.random.choice(dataset_val.image_ids, 50)\n","APs = []\n","for image_id in image_ids:\n","    # Load image and ground truth data\n","    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, inference_config,\n","                               image_id, use_mini_mask=False)\n","    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n","    # Run object detection\n","    results = model.detect([image], verbose=0)\n","    r = results[0]\n","    # Compute AP\n","    AP, precisions, recalls, overlaps =  utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n","                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n","    APs.append(AP)\n","    \n","print(\"mAP: \", np.mean(APs))"],"metadata":{"id":"SoPKj6pTjatf","executionInfo":{"status":"aborted","timestamp":1650393984300,"user_tz":-330,"elapsed":37,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import skimage\n","real_test_dir = '/content/gdrive/MyDrive/Mask_RCNN/datasets/images/images/val2016/'\n","image_paths = []\n","for filename in os.listdir(real_test_dir):\n","    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:\n","        image_paths.append(os.path.join(real_test_dir, filename))\n","\n","for image_path in image_paths:\n","    img = skimage.io.imread(image_path)\n","    img_arr = np.array(img)\n","    results = model.detect([img_arr], verbose=1)\n","    r = results[0]\n","    visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], \n","                                dataset_val.class_names, r['scores'], figsize=(5,5))"],"metadata":{"id":"AEAyEOzWp4dN","executionInfo":{"status":"aborted","timestamp":1650393984301,"user_tz":-330,"elapsed":38,"user":{"displayName":"Data Science","userId":"03488787834859186602"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Train.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}